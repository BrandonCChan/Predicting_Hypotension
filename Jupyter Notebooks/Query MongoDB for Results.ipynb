{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling data logged by sacred from a MongoDB database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def _connect_mongo(host, port, username, password, db):\n",
    "    \"\"\" Helper function for making a connection to mongo \"\"\"\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "    return conn[db]\n",
    "\n",
    "def read_mongo(db, collection, query={}, host='localhost', port=27017, username=None, password=None, no_id=True):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "    # Connect to MongoDB\n",
    "    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)\n",
    "    # Make a query to the specific DB and Collection\n",
    "    cursor = db[collection].find(query)\n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df =  pd.DataFrame(list(cursor))\n",
    "    # Delete the _id\n",
    "    if no_id:\n",
    "        del df['_id']\n",
    "    return df\n",
    "\n",
    "def parse_results(input_df, model_name):\n",
    "    \"\"\" Parse/filter results into a more \"managable\" dataframe\n",
    "        - Helps when you start storing too many models in one database or database gets messy\n",
    "    \n",
    "        inputs:\n",
    "        input_df -- pandas dataframe \n",
    "        model_name -- string (serves as an identifer for which model to get results for)\n",
    "        \n",
    "        output:\n",
    "        output_df -- pandas dataframe\n",
    "    \"\"\"\n",
    "    output_df = pd.DataFrame(columns=['accuracy','sensitivity','specificity','auc','config'])\n",
    "    i =0 \n",
    "    \n",
    "    for index, row in input_df.iterrows():\n",
    "        #print(row.config[\"model_name\"])\n",
    "        #obs = row.config[\"num_input\"]\n",
    "        #results = row.result\n",
    "        try:\n",
    "            if str(model_name) == str(row.config[\"model_name\"]):\n",
    "                name = row.experiment[\"name\"]\n",
    "                results = row.result\n",
    "                try:\n",
    "                    output_df.loc[i] = [results[0], results[1], results[2], results[3], row.config]\n",
    "                    i+=1\n",
    "                except:\n",
    "                    print('no results for', row.config[\"model_name\"], 'at index', str(index))\n",
    "        except:\n",
    "            print(\"cant read entry at index\", str(index))\n",
    "            \n",
    "    return output_df\n",
    "\n",
    "def make_matrix(df,metric,step=10):\n",
    "    #obs_times = list(range(10,61,step)) #list(range(60,4,-1)) #[60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10, 5] #[60, 45, 30, 15, 10, 5]\n",
    "    gap_times = list(range(10,61,step)) #[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60] #[5, 10, 15, 30, 45, 60]\n",
    "    num_tune_samples = list(range(0,51,step))\n",
    "    matrix = np.zeros((len(gap_times),len(num_tune_samples)))\n",
    "    print(matrix.shape)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in range(0,len(gap_times)):\n",
    "        gap = gap_times[i]\n",
    "        for j in range(0,len(num_tune_samples)):\n",
    "            samples = num_tune_samples[j]\n",
    "            try:\n",
    "                matrix[i,j] = df[(df.lag == gap) & (df.tune_samples == samples)][metric]\n",
    "            except:\n",
    "                print(df[(df.lag == gap) & (df.tune_samples == samples)][metric])\n",
    "                print(\"messed up value...\")\n",
    "                matrix[i,j] = 0\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe of all the experiments logged in the database\n",
    "df_whole = read_mongo(\"brandon_sandbox\", \"runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant read entry at index 18\n",
      "cant read entry at index 19\n",
      "cant read entry at index 20\n",
      "cant read entry at index 21\n",
      "no results for TEST at index 22\n",
      "no results for TEST at index 24\n",
      "no results for TEST at index 27\n",
      "no results for TEST at index 35\n",
      "no results for TEST at index 119\n"
     ]
    }
   ],
   "source": [
    "# Filter down the dataframe to only models with the name 'TEST'\n",
    "df_results = parse_results(df_whole,'TEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The parse results function filters out entries that 1) are errornous or 2) do not have logged results. This could be for a number of reasons such as termination of model training before it is finished running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>auc</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>{'batch_size': 64, 'checkpoint_dir': '/mnt/dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819459</td>\n",
       "      <td>{'batch_size': 64, 'checkpoint_dir': '/mnt/dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.717742</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.730749</td>\n",
       "      <td>{'batch_size': 64, 'checkpoint_dir': '/mnt/dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.787201</td>\n",
       "      <td>{'batch_size': 64, 'checkpoint_dir': '/mnt/dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.803330</td>\n",
       "      <td>{'batch_size': 64, 'checkpoint_dir': '/mnt/dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  sensitivity  specificity       auc  \\\n",
       "0  0.720000     0.760000     0.680000  0.758400   \n",
       "1  0.766129     0.709677     0.822581  0.819459   \n",
       "2  0.717742     0.854839     0.580645  0.730749   \n",
       "3  0.758065     0.903226     0.612903  0.787201   \n",
       "4  0.766129     0.870968     0.661290  0.803330   \n",
       "\n",
       "                                              config  \n",
       "0  {'batch_size': 64, 'checkpoint_dir': '/mnt/dat...  \n",
       "1  {'batch_size': 64, 'checkpoint_dir': '/mnt/dat...  \n",
       "2  {'batch_size': 64, 'checkpoint_dir': '/mnt/dat...  \n",
       "3  {'batch_size': 64, 'checkpoint_dir': '/mnt/dat...  \n",
       "4  {'batch_size': 64, 'checkpoint_dir': '/mnt/dat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The config is a dict that contains the various parameters used in that particular experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
